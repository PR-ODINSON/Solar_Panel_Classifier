{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running pipeline for: DJI_20250508151227_0001_V.JPG\n",
      "🧹 Cleared: output_tiles\n",
      "🧹 Cleared: tile_boxes\n",
      "🧹 Cleared: annotated_tiles\n",
      "\n",
      "0: 640x640 (no detections), 7.5ms\n",
      "Speed: 3.2ms preprocess, 7.5ms inference, 19.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 69.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 8.5ms\n",
      "Speed: 2.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 33.6ms\n",
      "Speed: 2.9ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.7ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 1 solar_panel, 7.4ms\n",
      "Speed: 2.4ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.7ms\n",
      "Speed: 3.4ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.4ms\n",
      "Speed: 3.4ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.9ms\n",
      "Speed: 3.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.9ms\n",
      "Speed: 3.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.2ms\n",
      "Speed: 2.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 8.2ms\n",
      "Speed: 2.9ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 4.3ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 3.2ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.4ms\n",
      "Speed: 3.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 2.6ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.4ms\n",
      "Speed: 3.3ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.4ms\n",
      "Speed: 3.2ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 3 solar_panels, 7.2ms\n",
      "Speed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.9ms\n",
      "Speed: 2.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.8ms\n",
      "Speed: 2.5ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.9ms\n",
      "Speed: 3.1ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.3ms\n",
      "Speed: 2.3ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x544 1 solar_panel, 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 solar_panel, 6.5ms\n",
      "Speed: 2.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 solar_panel, 6.6ms\n",
      "Speed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 solar_panel, 6.6ms\n",
      "Speed: 2.1ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x608 2 solar_panels, 34.3ms\n",
      "Speed: 2.5ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 solar_panel, 7.0ms\n",
      "Speed: 2.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x640 1 solar_panel, 8.4ms\n",
      "Speed: 4.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 3.1ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 181\u001b[39m\n\u001b[32m    179\u001b[39m tile_image_with_mapping(image_path, TILE_SIZE, TILE_DIR, \u001b[33m\"\u001b[39m\u001b[33mtile_metadata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m run_yolo_and_store_boxes()\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43mclassify_detected_panels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m restitch_tiles(metadata_csv, ANNOTATED_DIR, output_image_path)\n\u001b[32m    184\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Done: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_image_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mclassify_detected_panels\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m crop.shape[\u001b[32m0\u001b[39m] < \u001b[32m20\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m crop.shape[\u001b[32m1\u001b[39m] < \u001b[32m20\u001b[39m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m tensor = transform(\u001b[43mPILImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop\u001b[49m\u001b[43m)\u001b[49m).unsqueeze(\u001b[32m0\u001b[39m).to(device)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    137\u001b[39m     pred = model(tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\PIL\\Image.py:3326\u001b[39m, in \u001b[36mfromarray\u001b[39m\u001b[34m(obj, mode)\u001b[39m\n\u001b[32m   3323\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstrides\u001b[39m\u001b[33m'\u001b[39m\u001b[33m requires either tobytes() or tostring()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3324\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m3326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\PIL\\Image.py:3216\u001b[39m, in \u001b[36mfrombuffer\u001b[39m\u001b[34m(mode, size, data, decoder_name, *args)\u001b[39m\n\u001b[32m   3213\u001b[39m         im.readonly = \u001b[32m1\u001b[39m\n\u001b[32m   3214\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[32m-> \u001b[39m\u001b[32m3216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\PIL\\Image.py:3143\u001b[39m, in \u001b[36mfrombytes\u001b[39m\u001b[34m(mode, size, data, decoder_name, *args)\u001b[39m\n\u001b[32m   3118\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3119\u001b[39m \u001b[33;03mCreates a copy of an image memory from pixel data in a buffer.\u001b[39;00m\n\u001b[32m   3120\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3138\u001b[39m \u001b[33;03m:returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[32m   3139\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3141\u001b[39m _check_size(size)\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m im = \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.width != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m im.height != \u001b[32m0\u001b[39m:\n\u001b[32m   3145\u001b[39m     decoder_args: Any = args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\PIL\\Image.py:3108\u001b[39m, in \u001b[36mnew\u001b[39m\u001b[34m(mode, size, color)\u001b[39m\n\u001b[32m   3106\u001b[39m         im.palette = ImagePalette.ImagePalette()\n\u001b[32m   3107\u001b[39m         color = im.palette.getcolor(color_ints)\n\u001b[32m-> \u001b[39m\u001b[32m3108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m im._new(\u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# For Testing Entire Directory/Folder\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image, Image as PILImage\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# --- Constants ---\n",
    "INPUT_DIR = \"image_test/Drone Cracked Images\"\n",
    "OUTPUT_DIR = \"image_test_inference/Drone Cracked Images Annotated Resnet\"\n",
    "TILE_SIZE = 512\n",
    "TILE_DIR = \"output_tiles\"\n",
    "ANNOTATED_DIR = \"annotated_tiles\"\n",
    "BOXES_DIR = \"tile_boxes\"\n",
    "CLASSIFIER_PATH = \"resnet50_pv_classifier.pth\"\n",
    "YOLO_MODEL_PATH = \"runs/detect/train_yolo_v8_new_dataset4/weights/best.pt\"\n",
    "CLASS_NAMES = [\"Bird-drop\", \"Clean\", \"Dusty\", \"Physical-Damage\"]\n",
    "\n",
    "# --- Setup ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(TILE_DIR, exist_ok=True)\n",
    "os.makedirs(ANNOTATED_DIR, exist_ok=True)\n",
    "os.makedirs(BOXES_DIR, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# --- Clear Directories ---\n",
    "def clear_directories(*dirs):\n",
    "    for folder in dirs:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            continue\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.remove(file_path)\n",
    "        print(f\"🧹 Cleared: {folder}\")\n",
    "\n",
    "# --- Tiling ---\n",
    "def tile_image_with_mapping(image_path, tile_size=512, output_folder=TILE_DIR, metadata_file=\"tile_metadata.csv\"):\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    metadata_path = os.path.join(output_folder, metadata_file)\n",
    "\n",
    "    with open(metadata_path, mode='w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['tile_name', 'x_start', 'y_start', 'width', 'height'])\n",
    "\n",
    "        for y in range(0, height, tile_size):\n",
    "            for x in range(0, width, tile_size):\n",
    "                right = min(x + tile_size, width)\n",
    "                lower = min(y + tile_size, height)\n",
    "                tile = img.crop((x, y, right, lower)).convert(\"RGB\")\n",
    "                tile_name = f\"tile_{x}_{y}.jpg\"\n",
    "                tile.save(os.path.join(output_folder, tile_name))\n",
    "                writer.writerow([tile_name, x, y, right - x, lower - y])\n",
    "\n",
    "# --- YOLO Filter ---\n",
    "def is_likely_panel(crop):\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    brightness = np.mean(hsv[:, :, 2])\n",
    "    saturation = np.mean(hsv[:, :, 1])\n",
    "    avg_rgb = np.mean(crop, axis=(0, 1)).mean()\n",
    "    return (40 < brightness < 180) and (30 < saturation < 140) and (30 < avg_rgb < 180)\n",
    "\n",
    "# --- YOLO Inference ---\n",
    "def run_yolo_and_store_boxes():\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "    for fname in sorted(os.listdir(TILE_DIR)):\n",
    "        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "        tile_path = os.path.join(TILE_DIR, fname)\n",
    "        img = cv2.imread(tile_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        results = model(img, conf=0.75, iou=0.84)[0]\n",
    "        valid_boxes = []\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            crop = img[max(0, y1):min(img.shape[0], y2), max(0, x1):min(img.shape[1], x2)]\n",
    "            if crop.shape[0] < 20 or crop.shape[1] < 20 or not is_likely_panel(crop):\n",
    "                continue\n",
    "            valid_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "        if valid_boxes:\n",
    "            with open(os.path.join(BOXES_DIR, fname.replace(\".jpg\", \".json\")), \"w\") as f:\n",
    "                json.dump(valid_boxes, f)\n",
    "\n",
    "        cv2.imwrite(os.path.join(ANNOTATED_DIR, fname), img)\n",
    "\n",
    "# --- ResNet Classification ---\n",
    "def load_classifier():\n",
    "    model = resnet50()\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, len(CLASS_NAMES))\n",
    "    model.load_state_dict(torch.load(CLASSIFIER_PATH, map_location=\"cpu\"), strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def classify_detected_panels():\n",
    "    model = load_classifier()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for json_file in sorted(os.listdir(BOXES_DIR)):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        tile_name = json_file.replace(\".json\", \".jpg\")\n",
    "        tile_path = os.path.join(ANNOTATED_DIR, tile_name)\n",
    "        with open(os.path.join(BOXES_DIR, json_file), \"r\") as f:\n",
    "            boxes = json.load(f)\n",
    "\n",
    "        img = cv2.imread(tile_path)\n",
    "        rgb = img[:, :, ::-1]\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            crop = rgb[y1:y2, x1:x2]\n",
    "            if crop.shape[0] < 20 or crop.shape[1] < 20:\n",
    "                continue\n",
    "            tensor = transform(PILImage.fromarray(crop)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(tensor)\n",
    "                label = CLASS_NAMES[torch.argmax(pred, dim=1).item()]\n",
    "\n",
    "            color = (0, 255, 0) if label == \"Clean\" else (0, 0, 255)\n",
    "            center_x = x1 + (x2 - x1) // 2\n",
    "            center_y = y1 + (y2 - y1) // 2\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(img, label, (center_x - 20, center_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        cv2.imwrite(tile_path, img)\n",
    "\n",
    "# --- Restitch ---\n",
    "def restitch_tiles(metadata_csv, annotated_dir, save_path):\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    full_width = df['x_start'].max() + df['width'].max()\n",
    "    full_height = df['y_start'].max() + df['height'].max()\n",
    "    canvas = np.zeros((full_height, full_width, 3), dtype=np.uint8)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tile_path = os.path.join(annotated_dir, row['tile_name'])\n",
    "        tile = cv2.imread(tile_path)\n",
    "        if tile is None:\n",
    "            continue\n",
    "        x, y = int(row['x_start']), int(row['y_start'])\n",
    "        canvas[y:y+tile.shape[0], x:x+tile.shape[1]] = tile\n",
    "\n",
    "    cv2.imwrite(save_path, canvas)\n",
    "\n",
    "# --- Main Loop ---\n",
    "for image_name in sorted(os.listdir(INPUT_DIR)):\n",
    "    if not image_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Running pipeline for: {image_name}\")\n",
    "\n",
    "    clear_directories(TILE_DIR, BOXES_DIR, ANNOTATED_DIR)\n",
    "\n",
    "    image_path = os.path.join(INPUT_DIR, image_name)\n",
    "    output_image_name = os.path.splitext(image_name)[0] + \"_annotated.jpg\"\n",
    "    output_image_path = os.path.join(OUTPUT_DIR, output_image_name)\n",
    "    metadata_csv = os.path.join(TILE_DIR, \"tile_metadata.csv\")\n",
    "\n",
    "    tile_image_with_mapping(image_path, TILE_SIZE, TILE_DIR, \"tile_metadata.csv\")\n",
    "    run_yolo_and_store_boxes()\n",
    "    classify_detected_panels()\n",
    "    restitch_tiles(metadata_csv, ANNOTATED_DIR, output_image_path)\n",
    "\n",
    "    print(f\"✅ Done: {output_image_name}\")\n",
    "\n",
    "print(\"\\n🎯 All images processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad69583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running pipeline for: image_test/Drone Cracked Images/DJI_20250508151227_0001_V.jpg\n",
      "🧹 Cleared: output_tiles\n",
      "🧹 Cleared: tile_boxes\n",
      "🧹 Cleared: annotated_tiles\n",
      "\n",
      "0: 640x640 (no detections), 6.9ms\n",
      "Speed: 2.7ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.8ms\n",
      "Speed: 2.5ms preprocess, 6.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.6ms\n",
      "Speed: 2.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 2.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 1 solar_panel, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.9ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 2.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 2.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 2.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.7ms\n",
      "Speed: 2.2ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 2.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.9ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 2.4ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 3 solar_panels, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.1ms\n",
      "Speed: 2.8ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.2ms\n",
      "Speed: 2.4ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.2ms\n",
      "Speed: 2.5ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.5ms\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x544 1 solar_panel, 7.5ms\n",
      "Speed: 2.2ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 solar_panel, 6.7ms\n",
      "Speed: 2.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 solar_panel, 6.5ms\n",
      "Speed: 2.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 solar_panel, 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x608 2 solar_panels, 7.4ms\n",
      "Speed: 2.4ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 640x544 1 solar_panel, 7.2ms\n",
      "Speed: 2.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.0ms\n",
      "Speed: 2.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 7.3ms\n",
      "Speed: 2.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 576x640 2 solar_panels, 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x640 1 solar_panel, 9.2ms\n",
      "Speed: 2.6ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "✅ Done: image_test_inference/DJI_20250508151227_0001_V_annotated.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image, Image as PILImage\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# --- Constants ---\n",
    "INPUT_IMAGE = \"image_test/Drone Cracked Images/DJI_20250508151227_0001_V.jpg\"\n",
    "OUTPUT_IMAGE = \"image_test_inference_img/DJI_20250508151227_0001_V_annotated.jpg\"\n",
    "TILE_SIZE = 512\n",
    "TILE_DIR = \"output_tiles\"\n",
    "ANNOTATED_DIR = \"annotated_tiles\"\n",
    "BOXES_DIR = \"tile_boxes\"\n",
    "CLASSIFIER_PATH = \"resnet50_pv_classifier.pth\"\n",
    "YOLO_MODEL_PATH = \"runs/detect/train_yolo_v8_new_dataset4/weights/best.pt\"\n",
    "CLASS_NAMES = [\"Bird-drop\", \"Clean\", \"Dusty\", \"Physical-Damage\"]\n",
    "\n",
    "# --- Setup ---\n",
    "os.makedirs(\"image_test_inference_img\", exist_ok=True)\n",
    "os.makedirs(TILE_DIR, exist_ok=True)\n",
    "os.makedirs(ANNOTATED_DIR, exist_ok=True)\n",
    "os.makedirs(BOXES_DIR, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# --- Clear Directories ---\n",
    "def clear_directories(*dirs):\n",
    "    for folder in dirs:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            continue\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.remove(file_path)\n",
    "        print(f\"🧹 Cleared: {folder}\")\n",
    "\n",
    "# --- Tiling ---\n",
    "def tile_image_with_mapping(image_path, tile_size=512, output_folder=TILE_DIR, metadata_file=\"tile_metadata.csv\"):\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    metadata_path = os.path.join(output_folder, metadata_file)\n",
    "\n",
    "    with open(metadata_path, mode='w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['tile_name', 'x_start', 'y_start', 'width', 'height'])\n",
    "\n",
    "        for y in range(0, height, tile_size):\n",
    "            for x in range(0, width, tile_size):\n",
    "                right = min(x + tile_size, width)\n",
    "                lower = min(y + tile_size, height)\n",
    "                tile = img.crop((x, y, right, lower)).convert(\"RGB\")\n",
    "                tile_name = f\"tile_{x}_{y}.jpg\"\n",
    "                tile.save(os.path.join(output_folder, tile_name))\n",
    "                writer.writerow([tile_name, x, y, right - x, lower - y])\n",
    "\n",
    "# --- YOLO Filter ---\n",
    "def is_likely_panel(crop):\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    brightness = np.mean(hsv[:, :, 2])\n",
    "    saturation = np.mean(hsv[:, :, 1])\n",
    "    avg_rgb = np.mean(crop, axis=(0, 1)).mean()\n",
    "    return (40 < brightness < 180) and (30 < saturation < 140) and (30 < avg_rgb < 180)\n",
    "\n",
    "# --- YOLO Inference ---\n",
    "def run_yolo_and_store_boxes():\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "    for fname in sorted(os.listdir(TILE_DIR)):\n",
    "        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "        tile_path = os.path.join(TILE_DIR, fname)\n",
    "        img = cv2.imread(tile_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        results = model(img, conf=0.75, iou=0.84)[0]\n",
    "        valid_boxes = []\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            crop = img[max(0, y1):min(img.shape[0], y2), max(0, x1):min(img.shape[1], x2)]\n",
    "            if crop.shape[0] < 20 or crop.shape[1] < 20 or not is_likely_panel(crop):\n",
    "                continue\n",
    "            valid_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "        if valid_boxes:\n",
    "            with open(os.path.join(BOXES_DIR, fname.replace(\".jpg\", \".json\")), \"w\") as f:\n",
    "                json.dump(valid_boxes, f)\n",
    "\n",
    "        cv2.imwrite(os.path.join(ANNOTATED_DIR, fname), img)\n",
    "\n",
    "# --- ResNet Classification ---\n",
    "def load_classifier():\n",
    "    model = resnet50()\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, len(CLASS_NAMES))\n",
    "    model.load_state_dict(torch.load(CLASSIFIER_PATH, map_location=\"cpu\"), strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def classify_detected_panels():\n",
    "    model = load_classifier()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for json_file in sorted(os.listdir(BOXES_DIR)):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        tile_name = json_file.replace(\".json\", \".jpg\")\n",
    "        tile_path = os.path.join(ANNOTATED_DIR, tile_name)\n",
    "        with open(os.path.join(BOXES_DIR, json_file), \"r\") as f:\n",
    "            boxes = json.load(f)\n",
    "\n",
    "        img = cv2.imread(tile_path)\n",
    "        rgb = img[:, :, ::-1]\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            crop = rgb[y1:y2, x1:x2]\n",
    "            if crop.shape[0] < 20 or crop.shape[1] < 20:\n",
    "                continue\n",
    "            tensor = transform(PILImage.fromarray(crop)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(tensor)\n",
    "                label = CLASS_NAMES[torch.argmax(pred, dim=1).item()]\n",
    "\n",
    "            color = (0, 255, 0) if label == \"Clean\" else (0, 0, 255)\n",
    "            center_x = x1 + (x2 - x1) // 2\n",
    "            center_y = y1 + (y2 - y1) // 2\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(img, label, (center_x - 20, center_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        cv2.imwrite(tile_path, img)\n",
    "\n",
    "# --- Restitch ---\n",
    "def restitch_tiles(metadata_csv, annotated_dir, save_path):\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    full_width = df['x_start'].max() + df['width'].max()\n",
    "    full_height = df['y_start'].max() + df['height'].max()\n",
    "    canvas = np.zeros((full_height, full_width, 3), dtype=np.uint8)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tile_path = os.path.join(annotated_dir, row['tile_name'])\n",
    "        tile = cv2.imread(tile_path)\n",
    "        if tile is None:\n",
    "            continue\n",
    "        x, y = int(row['x_start']), int(row['y_start'])\n",
    "        canvas[y:y+tile.shape[0], x:x+tile.shape[1]] = tile\n",
    "\n",
    "    cv2.imwrite(save_path, canvas)\n",
    "\n",
    "# --- Run Pipeline for Single Image ---\n",
    "print(f\"\\n🔍 Running pipeline for: {INPUT_IMAGE}\")\n",
    "clear_directories(TILE_DIR, BOXES_DIR, ANNOTATED_DIR)\n",
    "tile_image_with_mapping(INPUT_IMAGE, TILE_SIZE, TILE_DIR, \"tile_metadata.csv\")\n",
    "run_yolo_and_store_boxes()\n",
    "classify_detected_panels()\n",
    "restitch_tiles(os.path.join(TILE_DIR, \"tile_metadata.csv\"), ANNOTATED_DIR, OUTPUT_IMAGE)\n",
    "print(f\"✅ Done: {OUTPUT_IMAGE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
